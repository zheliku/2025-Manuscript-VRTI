\section{RELATED WORK}
\subsection{VR Learning Theories}
Research indicates that applying immersive VR in educational contexts can enhance students' learning experiences and improve their understanding of knowledge content \cite{freina2015literature}. Additionally, understanding and applying VR learning theories can help educators and researchers create better learning materials and assessment tools, as well as develop more effective teaching methods \cite{matovu2023immersive}. Therefore, the application of learning theories in the effective design of VR learning experiences has become increasingly important \cite{marougkas2023virtual}. Common VR learning theories include Cognitive Load Theory, the ARCS Model of Motivation, and Immersion Theory.

Cognitive Load Theory was proposed by John Sweller in 1988 as a framework for understanding learning and cognition \cite{sweller1988cognitive}. The theory posits that cognitive load can be categorized into three types: intrinsic, extraneous, and germane. Intrinsic cognitive load is related to the inherent complexity of the learning material and is unavoidable, depending on the task's complexity and the learner's prior knowledge. Extraneous cognitive load arises from unnecessary elements in instructional design that do not contribute to learning objectives. Germane cognitive load is associated with the construction and automation of cognitive structures during learning, which facilitate understanding and retention. A common perspective is that breaking down complex tasks into smaller components can reduce intrinsic cognitive load; eliminating unnecessary information and distractions can minimize extraneous cognitive load; and practice and repetition can increase germane cognitive load by helping learners build and automate schemas \cite{baceviciute2022investigating}.

The ARCS Model of Motivation, proposed by John M. Keller in 1987, is a widely used motivational framework in education \cite{keller1987development}. The model suggests that the stimulation and maintenance of learning motivation depend on four core elements: Attention, Relevance, Confidence, and Satisfaction. By capturing learners' interest (Attention), ensuring the relevance of learning content (Relevance), boosting learners' confidence (Confidence), and providing a sense of achievement (Satisfaction), the ARCS model helps educators design more engaging and effective instructional strategies. This model is not only applicable to traditional classrooms but is also widely used in modern educational technologies, such as VR education, serving as an important theoretical tool for enhancing learning motivation.

Immersion refers to the sense of being physically present in a virtual environment during user interaction. Sherman et al. categorize immersion into physical/sensory immersion and mental immersion \cite{sherman2003understanding}. In virtual environments, users gather information through senses such as vision, hearing, and touch, processed by their perceptual systems to enable free navigation and manipulation of virtual objects, achieving physical immersion. Mental immersion refers to a state of deep engagement in the virtual environment. Both types of immersion significantly impact user experience. Features such as free navigation, first-person perspectives, realism, and interactivity contribute to learners' sense of immersion \cite{regenbrecht2002real,mikropoulos2006presence}, with interactivity being particularly influential \cite{schubert2001experience}.

In addition to the above VR learning theories, new theoretical perspectives have recently gained attention among researchers. Ryan R M et al. proposed the Self-Determination Theory (SDT), emphasizing autonomy, competence, and relatedness in the learning process. VR technology, by providing immersive and interactive learning environments, better satisfies these psychological needs, thereby enhancing students' motivation and learning outcomes \cite{ryan2024self}. Liu J et al. explored how the autonomy of VR learning environments and learner characteristics jointly influence learning outcomes and cognitive load. Their results suggest that changes in a single factor do not necessarily alter outcomes, as they are often determined by the interaction of both factors \cite{liu2024autonomy}. Lui A L C et al. reviewed recent studies on VR education using learning theories and proposed six design principles to facilitate the transition from traditional classroom education to VR, offering theoretically grounded recommendations for future educators \cite{lui2023theory}.As technology advances and educational needs evolve, VR learning theories and practices will continue to develop and improve.

\subsection{Immersive Physics Learning}
With the advancement of VR technology, its application in immersive physics learning has become increasingly widespread. For example, Georgiou et al. introduced immersive VR into the theoretical learning of special relativity, allowing students to experience and explore related physical phenomena from a first-person perspective, thereby enhancing learning efficiency and motivation \cite{georgiou2021learning}. Campos et al. utilized immersive learning environments in introductory physics courses to teach vector concepts, enabling students to manipulate vectors in a 3D grid, identify their components and angles, and measure their lengths. This approach fosters the potential for abstract conceptualization and operational skills, providing more intuitive explanations of physics concepts and their relationship to the physical world \cite{campos2022impact}. Additionally, AR technology enhances user experiences by overlaying virtual objects onto real environments, making experimental elements that are typically unobservable visible and aiding students in deeply understanding scientific principles and content \cite{pegrum2021augmented,prahani2022trend}. For instance, many researchers have visualized force vectors in mechanics and electric potential distributions in electromagnetism in 3D, promoting students' understanding and cognition of complex physical phenomena \cite{al2020effectiveness,teichrew2020augmented,ismail2019enhancing,boettcher2021using}.

Despite the growing attention and discussion surrounding immersive physics learning environments, most research and practices still focus on using visual feedback to convey information, neglecting other sensory interactions. As a direct connection between the human body and the physical world, touch provides immediate information about shape, texture, temperature, and weight, playing an important role in human perceptual experiences\cite{zhang2023active}. Existing research shows that incorporating haptic feedback can significantly enhance the effectiveness of virtual learning environments. For example, Shen Yang et al. introduced haptic feedback technology into the design of K-12 physics experiment scenario, evaluating its application in immersive learning through quasi-experiments. The results indicate that using haptic feedback in VR immersive learning significantly improves learners' sense of realism and interaction efficiency, although it does not significantly impact knowledge gains \cite{shen2023research}. Johnson-Glenberg et al. demonstrated that in STEM education within virtual reality environments, adding haptic information significantly reduces cognitive load and enhances students' understanding and retention of knowledge, particularly when students have prior knowledge \cite{johnson2023embodied}. Furthermore, embodied cognition theory in education suggests that through physical perception and manipulation, learners can transform concrete experiences into abstract knowledge, reconstructing and simulating actual experiences at a psychological level \cite{varela2017embodied}. Haptic technology, by simulating real-world interactions, makes virtual experiments more engaging and realistic, effectively improving learning efficiency and playing an indispensable role in helping students understand complex concepts \cite{shapiro2019embodied}. Therefore, integrating haptic interaction into immersive physics learning environments and exploring optimal application models for haptics in immersive physics learning should become a future research trend and focus.

Currently, immersive physics learning environments supporting haptic feedback can be broadly categorized into two types: haptic feedback devices and AR-based systems. Hpatic feedback devices generate controllable physical forces through motors, hydraulic systems, or pneumatic systems, acting on the user's hands or body to simulate real-world haptic feedback. These forces can include tension, thrust, resistance, etc., providing a controlled haptic experience. Common haptic feedback devices in immersive physics learning environments include haptic feedback joysticks/robotic arms (e.g., PHANTOM series), haptic gloves (e.g., HaptX gloves), and vibration-based devices (e.g., VR controllers). For example, Qi K et al. designed an experimental interaction environment with liquid containers, using the Novint Falcon haptic feedback device to explore the impact of haptic and visual feedback on understanding fundamental physics concepts related to buoyancy \cite{qi2020impact}. Acevedo P et al. created a visualization environment for electromagnetism, using Oculus Quest VR controllers to provide vibration feedback and study the effects of virtual reality environments and haptic feedback on students' perception and understanding of electromagnetism \cite{acevedo2022effects}. On the other hand, AR technology overlays virtual information onto the real world, providing immersive haptic feedback through touchable physical objects (e.g., simulated tools or models). For instance, Knierim P et al. used tangible replicas to replace physical components in laboratory experiments, providing haptic feedback and visualizing workflows through AR. They compared users' performance in setup time, experienced workload, measurement quality, and conceptual understanding of learning tasks \cite{knierim2020tangibility}. Liu Q et al. designed and developed an AR-based mobile simulation tool for middle school physics magnetic field concepts, investigating its impact on students' knowledge improvement and cognitive load \cite{liu2021effects}.

\subsection{Haptic Interaction}
Human haptic perception includes kinesthetic and cutaneous (skin) feedback. Kinesthetic feedback refers to the sense of body position and movement mediated by receptors in the skin, joints, skeletal muscles, and tendons; cutaneous feedback is related to stimuli detected by low-threshold mechanoreceptors beneath the skin, enabling the perception of natural or synthetic mechanical environments through touch \cite{hayward2004haptic}. With the continuous development of VR technology, the input of visual information provided solely by head-mounted devices no longer meets the demand for interaction, making haptic feedback increasingly important in VR environments. By introducing haptic technology, users receive haptic feedback when interacting with physical or virtual environments \cite{sreelakshmi2017haptic}. This not only compensates for the limitations of visual information but also provides users with richer and more realistic perceptual experiences, enabling them to intuitively understand objects and interactions in virtual environments.

Over the past decade, the advancement of haptic technology has led to a significant increase in related devices. Haptic devices, as carriers of haptic technology, enable users to interact intuitively and immersively with computer-generated virtual environments \cite{sreelakshmi2017haptic}. They can be broadly categorized into three types: grounded devices (also known as desktop devices), handheld devices, and wearable devices \cite{adilkhanov2022haptic}. Grounded devices, due to their size or functional characteristics, cannot be worn on a specific part of the user's body and thus have limited workspace. They can be further divided into graspable devices \cite{adel2018rendering,zarate2020contact,feick2023voxelhap} and touchable devices \cite{adilkhanov2020vibero,goetz2020patch}. Handheld devices can be picked up and held in the hand, offering portability, fewer mobility restrictions, and a larger workspace compared to grounded devices, but they do not provide completely free movement. Based on the type of actuation, handheld devices can be classified into direct-actuation devices \cite{sakr2020haptic,chen2019haptivec} and indirect-actuation devices \cite{kovacs2020haptic}. Direct-actuation devices act directly on the user's hand through handles and end-effectors, while indirect-actuation devices alter the center of gravity to provide different haptic cues. Wearable devices, depending on the part of the body they are worn on, can be divided into haptic gloves \cite{ozioko2022smart}, finger-worn devices \cite{chinello2019modular,preechayasomboon2021haplets}, and arm-worn devices \cite{zhao2020wearable,pezent2022explorations}.

Unlike traditional haptic devices, hand-based haptic interaction focuses on the integration of virtual hand models with haptic rendering. Related research includes geometric and physical modeling of virtual hands, collision detection and force calculation based on virtual hands, and kinesthetic and haptic rendering \cite{tong2023survey}. Two primary challenges persist: (a) simulating haptic feedback using real objects during VR experiences, and (b) achieving spatial congruence between real/virtual hands and objects for seamless interaction (termed virtual-real alignment in this study). André Zenner et al. demonstrated that dynamic hardware adjustments combined with software-based visual compensation can significantly enhance the realism and robustness of haptic feedback, though such approaches remain nascent \cite{zenner2021combining}. In recent years, this research direction has garnered increasing attention. For example, M. Salvato et al. used gesture-tracking time series and virtual object geometry to predict when users would initiate touch interactions with virtual objects, improving haptic feedback in mixed reality \cite{salvato2022predicting}. H. Barreiro et al. proposed a novel particle-based viscoplastic interaction model and an optimization-based ultrasonic rendering algorithm, combined with air-based haptic rendering technology, to simulate interactions with clay-like materials and provide highly realistic haptic feedback \cite{barreiro2021natural}. Salagean A et al. applied ultrasonic mid-air haptic technology to VR environments, where participants watched a virtual hand being stroked by a feather while receiving stimuli on the glabrous skin of the palm and the hairy skin of the back of the hand. The results showed that ultrasonic stimuli on the palm were more intense \cite{salagean2022virtual}.